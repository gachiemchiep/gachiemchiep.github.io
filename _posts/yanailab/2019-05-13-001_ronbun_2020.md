---
title: "2020年度、論文紹介"
excerpt: "2020年度、論文紹介."
categories: 
  - yanailab
comments: false
published: true
toc: true
support: true
order: 9
author: vugia.truong
---
# 一覧

## IMP: Instance Mask Projection for High Accuracy Semantic Segmentation of Things

服のデータセット（ModaNet）で、2019年のSOTAとくらべ20%のmIOUを増加、しかしcityscapeのデータセットの場合数％しか増加しない -> 服の領域分割専用のsematic segmentatorかな

## ArcFace: Additive Angular Margin Loss for Deep Face Recognition

[source code : mxnet](https://github.com/deepinsight/insightface/tree/master/recognition)

proposed an **Additive Angular Margin Loss** function、

## GradNet: Gradient-Guided Network for Visual Object Tracking

Nothing special pass

## FET-GAN: Font and Effect Transfer via K-shot Adaptive Instance Normalization

GAN を用いて、Font生成　、 [source code](https://github.com/liweileev/FET-GAN)

## Specifying Object Attributes and Relations in Interactive Scene Generation

ICCV 2019 , [source cdode](https://github.com/ashual/scene_generation), Generating image using scene-text-grapth , [Youtube GUI](https://youtu.be/V2v0qEPsjr0?t=194)

## 0519: A Simple Baseline for Multi-Object Tracking 

-> [source code](https://github.com/ifzhang/FairMOT)
-> one-shot multiple object tracking
    -> one-shot object detectionと同じ意味、one-shot, few-shot learningの意味ではない
    -> 多目的のネットワークを学習、従来のMOTは　検出とRe-ID　の2つの段階で行います。
    FairMOTは検出＋Re-IDを同時に行い、一つの段階になりました。
    そろで速度が30FPS達成した、他の工夫もある、精度はSOTAになりました

-> jil の tracker は [simple detector](https://arxiv.org/pdf/1703.07402.pdf) のやり方で工夫できるかもしれません

## 0519: HoloGAN: Unsupervised Learning of 3D Representations From Natural Images

-> next

## 0522: EGO-TOPO: Environment Affordances from Egocentric Video

next

## 0526: Image2StyleGAN: How to Embed Images Into the StyleGAN Latent Space?

similar source code at [github](https://github.com/pacifinapacific/StyleGAN_LatentEditor)

解説記事も [quita](https://qiita.com/pacifinapacific/items/1d6cca0ff4060e12d336)

終了

## 0526: Semi-Supervised Classification with Graph Convolutional Networks

全く理解できない

## 0529:  Fast Image Processing with Fully-Convolutional Networks,

[source code](https://github.com/CQFIO/FastImageProcessing)

[demo video](https://www.youtube.com/watch?v=eQyfHgLx8Dc)

image processing (down-sampling, up-sampling, dehazingなど)を深層学習（ネットワーク名：CAN）で行います。
処理時間の大幅を短縮できました。

## 0529: Gabriella: An Online System for Real-Time Activity Detection in Untrimmed Surveillance Videos,

-> security video surveilliance
-> run very fast, faster than real-time (>=45fps) 
-> can detect multiple action inside vide

## 0605 Example-Guided Image Synthesis across Arbitrary Scenes using Masked Spatial-Channel Attention and Self-Supervision

-> pass

## 0605 Cross-domain Correspondence Learning for Exemplar-based Image Translation

Exemplar-based image translation : example = styleの画像
見本画像（Examplar）を用いて、InputのSketch画像を完成する方法を提案
  -＞　応用例：　Fashionの画像を回転するなど
  -> なんか良いらしい

[paper page](https://panzhang0212.github.io/CoCosNet/)

## 0609 Deep Multi-Modal Image Correspondence Learning

-> 不動産のデータセットを利用 : [lifull](https://www.nii.ac.jp/dsc/idr/lifull/)
-> 古いのでpass

## 0609 Zero-shot Ingredient Recognition by Multi-Relational Graph Convolutional Network,

Food 関係、pass

## 0612 : G3AN: Disentangling Appearance and Motion for Video Generation, CVPR, (2020).

-> GAN : pass

## 0612 : Large-Scale Object Detection in the Wild from Imbalanced Multi-Labels, CVPR, (2020).

Open Images public test 2018で60.90 mAPの最良の単一モデル

Hybrid training schedulerを用いたSoft-balance法を提案すること
で、非常に不均衡なラベル分布問題に効果的に対処することが可
能である

明示的・暗黙的なマルチラベル問題　:？？？？？

-> 強大なデータセットに役に立つ

## 0616 BachGAN: High-Resolution Image Synthesis from Salient Object Layout, CVPR, (2020).

source code : [github](https://github.com/Cold-Winter/BachGAN)

-> GAN のでpass

## 0619 Mask Encoding for Single Shot Instance Segmentation, CVPR, (2020).

-> pass

## 0619 Visual Relations Augmented Cross-modal Retrieval, ACM ICMR, (2020).

-> cross-modal retrieval (CMR) -> pass

## 0623 Improving Action Segmentation via Graph Based Temporal Reasoning, CVPR, (2020).

  -> pass

## 0623 Editing in Style: Uncovering the Local Semantics of GANs, CVPR, (2020).

  https://github.com/IVRL/GANLocalEditing  : Gan for local editting

## 0626 Total3DUnderstanding: Joint Layout, Object Pose and Mesh Reconstructionfor Indoor Scenes from a Single Image, CVPR, pp.55-64, (2020)

 -> read this if we need to work with the 3d object detection
 -> current 3D object detection SOTA : https://github.com/open-mmlab/OpenPCDet

## 0626  Conditional Channel Gated Networks for Task-Aware Continual Learning, CVPR, (2020).

## 0630  Temporal Pyramid Network for Action Recognition, CVPR, (2020)

-> next

## 0710 Something-Else: Compositional Action Recognition with Spatial-Temporal Interaction Networks, CVPR, (2020).

動画認識、ー＞次

## 0710 Swapping Autoencoder for Deep Image Manipulation, arXiv:2007.00653v1, (2020).

-> image manipulation : texture swapping, ... 

## 0714 3D Imaging, Modeling, Processing, Visualization and Transmission, pp.145-152, (2001).

-> ICP , next

## 0714 ADINet: Attribute driven incremental network for retinal image classification, CVPR, (2020).

-> 医療の画像認識、pass

## 0717 : X3D: Expanding Architectures for Efficient Video Recognition, CVPR, (2020).

-> 動画認識の**低計算化**　、X3D-XLとSlowFast+NL(SOTA)とほぼ同じ精度、演算量は5倍より少ない

## 0717 :  CookGAN:CausalitybasedText-to-ImageSynthesis, CVPR, (2020).

料理二関する画像研究に以下のタスクに実験した
-> Ingredient recognition: image -> ingredient
-> image to recipe retrieval 
->  image to image retrieval 
-> content manipulability : add ingredients, mibus ingredients, replace ingredients

## 0721 : ManiGAN: Text-Guided Image Manipulation, CVPR, (2020).

text -> image : 多くの内容はControlGANから借りる. [Source code of ControlGAN](https://github.com/mrlibw/ControlGAN)

## 0721 : : PlaneRCNN:3D Plane Detection and Reconstruction from a Single Image, CVPR, (2019).

[source code PlaneRCNN](https://github.com/NVlabs/planercnn) : community, non-commercial

単一RGB画像から平面領域を分割するPlaneRCNNを提案
PlaneRCNNは平面領域、回帰平面パラメータ、インスタンスマスクを検出
セグメンテーションマスクをグローバルに洗練
パフォーマンス向上のため別視点画像の利用
細かい平面を分割できる手法として最高精度を記憶

## 0728 : Fast Online Object Tracking and Segmentation: A Unifying Approach, CVPR, (2019).

SiamMask提案、Source-codeは [SenseTime Pysot](https://github.com/STVIR/pysot)にある

## 0728 : World-Consistent Video-to-Video Synthesis, ECCV, (2020).

[https://nvlabs.github.io/wc-vid2vid/](https://nvlabs.github.io/wc-vid2vid/)

Video-to-Video Synthesis = Semantic Segmentation (Segmentationデータセットのlabel) + depth情報から　動画を生成する

ー＞　VidtoVid研究は結局なのため？？？

# 個人が注目する論文