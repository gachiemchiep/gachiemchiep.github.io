---
title: "2020年度、論文紹介"
excerpt: "2020年度、論文紹介."
categories: 
  - yanailab
comments: false
published: true
toc: true
support: true
order: 9
author: vugia.truong
---
# 一覧

## IMP: Instance Mask Projection for High Accuracy Semantic Segmentation of Things

服のデータセット（ModaNet）で、2019年のSOTAとくらべ20%のmIOUを増加、しかしcityscapeのデータセットの場合数％しか増加しない -> 服の領域分割専用のsematic segmentatorかな

## ArcFace: Additive Angular Margin Loss for Deep Face Recognition

[source code : mxnet](https://github.com/deepinsight/insightface/tree/master/recognition)

proposed an **Additive Angular Margin Loss** function、

## GradNet: Gradient-Guided Network for Visual Object Tracking

Nothing special pass

## FET-GAN: Font and Effect Transfer via K-shot Adaptive Instance Normalization

GAN を用いて、Font生成　、 [source code](https://github.com/liweileev/FET-GAN)

## Specifying Object Attributes and Relations in Interactive Scene Generation

ICCV 2019 , [source cdode](https://github.com/ashual/scene_generation), Generating image using scene-text-grapth , [Youtube GUI](https://youtu.be/V2v0qEPsjr0?t=194)

## 0519: A Simple Baseline for Multi-Object Tracking 

-> [source code](https://github.com/ifzhang/FairMOT)
-> one-shot multiple object tracking
    -> one-shot object detectionと同じ意味、one-shot, few-shot learningの意味ではない
    -> 多目的のネットワークを学習、従来のMOTは　検出とRe-ID　の2つの段階で行います。
    FairMOTは検出＋Re-IDを同時に行い、一つの段階になりました。
    そろで速度が30FPS達成した、他の工夫もある、精度はSOTAになりました

-> jil の tracker は [simple detector](https://arxiv.org/pdf/1703.07402.pdf) のやり方で工夫できるかもしれません

## 0519: HoloGAN: Unsupervised Learning of 3D Representations From Natural Images

-> next

## 0522: EGO-TOPO: Environment Affordances from Egocentric Video

next

## 0526: Image2StyleGAN: How to Embed Images Into the StyleGAN Latent Space?

similar source code at [github](https://github.com/pacifinapacific/StyleGAN_LatentEditor)

解説記事も [quita](https://qiita.com/pacifinapacific/items/1d6cca0ff4060e12d336)

終了

## 0526: Semi-Supervised Classification with Graph Convolutional Networks

全く理解できない

## 0529:  Fast Image Processing with Fully-Convolutional Networks,

[source code](https://github.com/CQFIO/FastImageProcessing)

[demo video](https://www.youtube.com/watch?v=eQyfHgLx8Dc)

image processing (down-sampling, up-sampling, dehazingなど)を深層学習（ネットワーク名：CAN）で行います。
処理時間の大幅を短縮できました。

## 0529: Gabriella: An Online System for Real-Time Activity Detection in Untrimmed Surveillance Videos,

-> security video surveilliance
-> run very fast, faster than real-time (>=45fps) 
-> can detect multiple action inside vide

## 0605 Example-Guided Image Synthesis across Arbitrary Scenes using Masked Spatial-Channel Attention and Self-Supervision

-> pass

## 0605 Cross-domain Correspondence Learning for Exemplar-based Image Translation

Exemplar-based image translation : example = styleの画像
見本画像（Examplar）を用いて、InputのSketch画像を完成する方法を提案
  -＞　応用例：　Fashionの画像を回転するなど
  -> なんか良いらしい

[paper page](https://panzhang0212.github.io/CoCosNet/)

## 0609 Deep Multi-Modal Image Correspondence Learning

-> 不動産のデータセットを利用 : [lifull](https://www.nii.ac.jp/dsc/idr/lifull/)
-> 古いのでpass

## 0609 Zero-shot Ingredient Recognition by Multi-Relational Graph Convolutional Network,

Food 関係、pass

# 個人が注目する論文